{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk langgraph-prebuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# This will be a tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide a by b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "llm = ChatGroq(model=os.getenv(\"GROQ_MODEL_NAME\"))\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine the control flow\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Show\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_g4xh)\n",
      " Call ID: call_g4xh\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "6\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 2 and 3 is 6.\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Browsing History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='7b979261-61ef-4777-8521-bccc9e02d61e'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_g4xh', 'function': {'arguments': '{\"a\": 2, \"b\": 3}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 373, 'total_tokens': 392, 'completion_time': 0.069090909, 'prompt_time': 0.02408239, 'queue_time': 0.05424493100000001, 'total_time': 0.093173299}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_6507bcfb6f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--01f860fe-b660-4790-80b4-411b1e67ae56-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_g4xh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 373, 'output_tokens': 19, 'total_tokens': 392}), ToolMessage(content='6', name='multiply', id='6b33c988-a842-4110-8d48-badf4c11c28b', tool_call_id='call_g4xh'), AIMessage(content='The result of multiplying 2 and 3 is 6.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 403, 'total_tokens': 417, 'completion_time': 0.050909091, 'prompt_time': 0.033468219, 'queue_time': 0.055414361, 'total_time': 0.08437731}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'finish_reason': 'stop', 'logprobs': None}, id='run--49a3170d-305e-4a03-9c77-8e6f7da5b23b-0', usage_metadata={'input_tokens': 403, 'output_tokens': 14, 'total_tokens': 417})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f03028b-8e1e-6daa-8003-4a8706eae9fc'}}, metadata={'source': 'loop', 'writes': {'assistant': {'messages': [AIMessage(content='The result of multiplying 2 and 3 is 6.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 403, 'total_tokens': 417, 'completion_time': 0.050909091, 'prompt_time': 0.033468219, 'queue_time': 0.055414361, 'total_time': 0.08437731}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'finish_reason': 'stop', 'logprobs': None}, id='run--49a3170d-305e-4a03-9c77-8e6f7da5b23b-0', usage_metadata={'input_tokens': 403, 'output_tokens': 14, 'total_tokens': 417})]}}, 'step': 3, 'parents': {}, 'thread_id': '1'}, created_at='2025-05-13T18:33:10.712455+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f03028b-8c1e-6582-8002-767a09b4fcdb'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state({'configurable': {'thread_id': '1'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states = [s for s in graph.get_state_history(thread)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='7b979261-61ef-4777-8521-bccc9e02d61e')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f03028b-853e-601e-8000-7dabe0b70653'}}, metadata={'source': 'loop', 'writes': None, 'step': 0, 'parents': {}, 'thread_id': '1'}, created_at='2025-05-13T18:33:09.781501+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f03028b-853b-6c2e-bfff-bb0a40c9482e'}}, tasks=(PregelTask(id='062aa05a-7d43-e7e1-ee80-65672518cabf', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result={'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_g4xh', 'function': {'arguments': '{\"a\": 2, \"b\": 3}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 373, 'total_tokens': 392, 'completion_time': 0.069090909, 'prompt_time': 0.02408239, 'queue_time': 0.05424493100000001, 'total_time': 0.093173299}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_6507bcfb6f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--01f860fe-b660-4790-80b4-411b1e67ae56-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_g4xh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 373, 'output_tokens': 19, 'total_tokens': 392})]}),), interrupts=())"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_states[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://camo.githubusercontent.com/8bfbb7c4ccc17b02d5facd27a3f6953723800870ac06c6d26e8e8eb5ce7215d0/68747470733a2f2f63646e2e70726f642e776562736974652d66696c65732e636f6d2f3635623863643732383335636565616364343434396135332f3636646262303338323131623534343839383537306265335f74696d652d74726176656c312e706e67)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replaying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://camo.githubusercontent.com/e741d4265a3a051ffbad7c6929a9207dadcda465b708201d032fd73df02ecbdc/68747470733a2f2f63646e2e70726f642e776562736974652d66696c65732e636f6d2f3635623863643732383335636565616364343434396135332f3636646262303338613062643334623534316337386662385f74696d652d74726176656c322e706e67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_replay = all_states[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='7b979261-61ef-4777-8521-bccc9e02d61e')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f03028b-853e-601e-8000-7dabe0b70653'}}, metadata={'source': 'loop', 'writes': None, 'step': 0, 'parents': {}, 'thread_id': '1'}, created_at='2025-05-13T18:33:09.781501+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f03028b-853b-6c2e-bfff-bb0a40c9482e'}}, tasks=(PregelTask(id='062aa05a-7d43-e7e1-ee80-65672518cabf', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result={'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_g4xh', 'function': {'arguments': '{\"a\": 2, \"b\": 3}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 373, 'total_tokens': 392, 'completion_time': 0.069090909, 'prompt_time': 0.02408239, 'queue_time': 0.05424493100000001, 'total_time': 0.093173299}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_6507bcfb6f', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--01f860fe-b660-4790-80b4-411b1e67ae56-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_g4xh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 373, 'output_tokens': 19, 'total_tokens': 392})]}),), interrupts=())"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='7b979261-61ef-4777-8521-bccc9e02d61e')]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_replay.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('assistant',)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_replay.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f03028b-853e-601e-8000-7dabe0b70653'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_replay.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_ha5f)\n",
      " Call ID: call_ha5f\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "6\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 2 and 3 is 6.\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://camo.githubusercontent.com/80e8b29ceb73669d1c1cb2550b320d5fa37fc401c4b009c1afb7edaf58cda76a/68747470733a2f2f63646e2e70726f642e776562736974652d66696c65732e636f6d2f3635623863643732383335636565616364343434396135332f3636646262303338663839663264383437656535633333365f74696d652d74726176656c332e706e67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='7b979261-61ef-4777-8521-bccc9e02d61e')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fork = all_states[-2]\n",
    "to_fork.values[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f03028b-853e-601e-8000-7dabe0b70653'}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fork.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fork_config = graph.update_state(\n",
    "    to_fork.config,\n",
    "    {\"messages\": [HumanMessage(content='Multiply 5 and 3', \n",
    "                               id=to_fork.values[\"messages\"][0].id)]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0302a1-cccf-6bd8-8001-5a1f6d8f4f33'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fork_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Multiply 5 and 3', additional_kwargs={}, response_metadata={}, id='7b979261-61ef-4777-8521-bccc9e02d61e')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_states = [state for state in graph.get_state_history(thread) ]\n",
    "all_states[0].values[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 5 and 3', additional_kwargs={}, response_metadata={}, id='7b979261-61ef-4777-8521-bccc9e02d61e')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0302a1-cccf-6bd8-8001-5a1f6d8f4f33'}}, metadata={'source': 'update', 'writes': {'__start__': {'messages': [HumanMessage(content='Multiply 5 and 3', additional_kwargs={}, response_metadata={}, id='7b979261-61ef-4777-8521-bccc9e02d61e')]}}, 'step': 1, 'parents': {}, 'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f03028b-853e-601e-8000-7dabe0b70653'}, created_at='2025-05-13T18:43:07.844076+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f03028b-853e-601e-8000-7dabe0b70653'}}, tasks=(PregelTask(id='39f6e6cd-35b4-8466-6b5a-89cad0b32fc1', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state({'configurable': {'thread_id': '1'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 5 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_c726)\n",
      " Call ID: call_c726\n",
      "  Args:\n",
      "    a: 5\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "15\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 5 and 3 is 15.\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, fork_config, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 5 and 3', additional_kwargs={}, response_metadata={}, id='7b979261-61ef-4777-8521-bccc9e02d61e'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_c726', 'function': {'arguments': '{\"a\": 5, \"b\": 3}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 373, 'total_tokens': 392, 'completion_time': 0.166680443, 'prompt_time': 0.033107067, 'queue_time': 0.059402793, 'total_time': 0.19978751}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a23d21a5-6986-4bb6-a0d1-a083cc4a1c1e-0', tool_calls=[{'name': 'multiply', 'args': {'a': 5, 'b': 3}, 'id': 'call_c726', 'type': 'tool_call'}], usage_metadata={'input_tokens': 373, 'output_tokens': 19, 'total_tokens': 392}), ToolMessage(content='15', name='multiply', id='224a5736-80c7-47f1-aba8-4a74d65c614c', tool_call_id='call_c726'), AIMessage(content='The result of multiplying 5 and 3 is 15.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 403, 'total_tokens': 417, 'completion_time': 0.050909091, 'prompt_time': 0.026637423, 'queue_time': 0.061800237, 'total_time': 0.077546514}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'finish_reason': 'stop', 'logprobs': None}, id='run--6cccaa61-0304-48a9-8ccd-9894b913c02f-0', usage_metadata={'input_tokens': 403, 'output_tokens': 14, 'total_tokens': 417})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0302a3-0dba-6eda-8004-87bce36648e3'}}, metadata={'source': 'loop', 'writes': {'assistant': {'messages': [AIMessage(content='The result of multiplying 5 and 3 is 15.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 403, 'total_tokens': 417, 'completion_time': 0.050909091, 'prompt_time': 0.026637423, 'queue_time': 0.061800237, 'total_time': 0.077546514}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'finish_reason': 'stop', 'logprobs': None}, id='run--6cccaa61-0304-48a9-8ccd-9894b913c02f-0', usage_metadata={'input_tokens': 403, 'output_tokens': 14, 'total_tokens': 417})]}}, 'step': 4, 'parents': {}, 'thread_id': '1'}, created_at='2025-05-13T18:43:41.494842+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0302a3-0bc5-6d6e-8003-d8b02e508316'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state({'configurable': {'thread_id': '1'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "client = get_client(url=\"http://127.0.0.1:2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Assistant Node--------------------\n",
      "{'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'call_n445', 'function': {'arguments': '{\"a\": 2, \"b\": 3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'token_usage': {'completion_tokens': 19, 'prompt_tokens': 374, 'total_tokens': 393, 'completion_time': 0.069090909, 'prompt_time': 0.031841398, 'queue_time': 0.054882761999999995, 'total_time': 0.100932307}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--d10e8f11-bf36-4b3e-8f3f-24edfeed9669-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_n445', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 374, 'output_tokens': 19, 'total_tokens': 393}}\n"
     ]
    }
   ],
   "source": [
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "thread = await client.threads.create()\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id = \"agent\",\n",
    "    input=initial_input,\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    if chunk.data:\n",
    "        assisant_node = chunk.data.get('assistant', {}).get('messages', [])\n",
    "        tool_node = chunk.data.get('tools', {}).get('messages', [])\n",
    "        if assisant_node:\n",
    "            print(\"-\" * 20+\"Assistant Node\"+\"-\" * 20)\n",
    "            print(assisant_node[-1])\n",
    "        elif tool_node:\n",
    "            print(\"-\" * 20+\"Tools Node\"+\"-\" * 20)\n",
    "            print(tool_node[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'values': {'messages': [{'content': 'Multiply 2 and 3',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'human',\n",
       "    'name': None,\n",
       "    'id': '5e674f25-a94f-4c81-afdb-e1205612726c',\n",
       "    'example': False}]},\n",
       " 'next': ['assistant'],\n",
       " 'tasks': [{'id': 'eb6835c6-dae4-cad6-5492-7f9df5dd171c',\n",
       "   'name': 'assistant',\n",
       "   'path': ['__pregel_pull', 'assistant'],\n",
       "   'error': None,\n",
       "   'interrupts': [],\n",
       "   'checkpoint': None,\n",
       "   'state': None,\n",
       "   'result': {'messages': [{'content': '',\n",
       "      'additional_kwargs': {'tool_calls': [{'id': 'call_n445',\n",
       "         'function': {'arguments': '{\"a\": 2, \"b\": 3}', 'name': 'multiply'},\n",
       "         'type': 'function'}]},\n",
       "      'response_metadata': {'token_usage': {'completion_tokens': 19,\n",
       "        'prompt_tokens': 374,\n",
       "        'total_tokens': 393,\n",
       "        'completion_time': 0.069090909,\n",
       "        'prompt_time': 0.031841398,\n",
       "        'queue_time': 0.054882761999999995,\n",
       "        'total_time': 0.100932307},\n",
       "       'model_name': 'llama-3.3-70b-versatile',\n",
       "       'system_fingerprint': 'fp_3f3b593e33',\n",
       "       'finish_reason': 'tool_calls',\n",
       "       'logprobs': None},\n",
       "      'type': 'ai',\n",
       "      'name': None,\n",
       "      'id': 'run--d10e8f11-bf36-4b3e-8f3f-24edfeed9669-0',\n",
       "      'example': False,\n",
       "      'tool_calls': [{'name': 'multiply',\n",
       "        'args': {'a': 2, 'b': 3},\n",
       "        'id': 'call_n445',\n",
       "        'type': 'tool_call'}],\n",
       "      'invalid_tool_calls': [],\n",
       "      'usage_metadata': {'input_tokens': 374,\n",
       "       'output_tokens': 19,\n",
       "       'total_tokens': 393}}]}}],\n",
       " 'metadata': {'user-agent': 'langgraph-sdk-py/0.1.69',\n",
       "  'x-request-id': 'de755621-c06e-4dab-a126-b497f95415f1',\n",
       "  'langgraph_auth_user': None,\n",
       "  'langgraph_auth_user_id': '',\n",
       "  'langgraph_auth_permissions': [],\n",
       "  'langgraph_request_id': 'de755621-c06e-4dab-a126-b497f95415f1',\n",
       "  'graph_id': 'agent',\n",
       "  'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',\n",
       "  'user_id': '',\n",
       "  'created_by': 'system',\n",
       "  'run_attempt': 1,\n",
       "  'langgraph_version': '0.4.3',\n",
       "  'langgraph_plan': 'developer',\n",
       "  'langgraph_host': 'self-hosted',\n",
       "  'langgraph_api_url': 'http://127.0.0.1:2024',\n",
       "  'run_id': '1f0302ac-60ae-6368-b8ee-7dcf86312549',\n",
       "  'thread_id': 'a19a5e06-ffe6-46d8-8164-f12832494bf6',\n",
       "  'source': 'loop',\n",
       "  'writes': None,\n",
       "  'step': 0,\n",
       "  'parents': {}},\n",
       " 'created_at': '2025-05-13T18:47:52.492100+00:00',\n",
       " 'checkpoint': {'checkpoint_id': '1f0302ac-676d-63ac-8000-20d4e4484a0b',\n",
       "  'thread_id': 'a19a5e06-ffe6-46d8-8164-f12832494bf6',\n",
       "  'checkpoint_ns': ''},\n",
       " 'parent_checkpoint': {'checkpoint_id': '1f0302ac-675e-6fe6-bfff-b508c11bf648',\n",
       "  'thread_id': 'a19a5e06-ffe6-46d8-8164-f12832494bf6',\n",
       "  'checkpoint_ns': ''},\n",
       " 'checkpoint_id': '1f0302ac-676d-63ac-8000-20d4e4484a0b',\n",
       " 'parent_checkpoint_id': '1f0302ac-675e-6fe6-bfff-b508c11bf648'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = await client.threads.get_history(thread['thread_id'])\n",
    "to_replay = states[-2]\n",
    "to_replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving new event of type: metadata...\n",
      "{'run_id': '1f0302ad-b0e8-6288-9beb-70213e882162', 'attempt': 1}\n",
      "\n",
      "\n",
      "\n",
      "Receiving new event of type: values...\n",
      "{'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '5e674f25-a94f-4c81-afdb-e1205612726c', 'example': False}]}\n",
      "\n",
      "\n",
      "\n",
      "Receiving new event of type: values...\n",
      "{'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '5e674f25-a94f-4c81-afdb-e1205612726c', 'example': False}, {'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'call_btn2', 'function': {'arguments': '{\"a\": 2, \"b\": 3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'token_usage': {'completion_tokens': 19, 'prompt_tokens': 374, 'total_tokens': 393, 'completion_time': 0.069090909, 'prompt_time': 0.032375037, 'queue_time': 0.055120223, 'total_time': 0.101465946}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_9a8b91ba77', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--7217f67a-afa4-482e-89c3-cb2ffaf0f54c-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_btn2', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 374, 'output_tokens': 19, 'total_tokens': 393}}]}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input=None,\n",
    "    stream_mode=\"values\",\n",
    "    checkpoint_id=to_replay['checkpoint_id']\n",
    "):      \n",
    "    print(f\"Receiving new event of type: {chunk.event}...\")\n",
    "    print(chunk.data)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Assistant Node--------------------\n",
      "{'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'call_0ns1', 'function': {'arguments': '{\"a\": 2, \"b\": 3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'token_usage': {'completion_tokens': 19, 'prompt_tokens': 374, 'total_tokens': 393, 'completion_time': 0.089718869, 'prompt_time': 0.103931565, 'queue_time': 0.054431755, 'total_time': 0.193650434}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--f0a90237-1075-4f15-b939-9ff3c50815ff-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_0ns1', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 374, 'output_tokens': 19, 'total_tokens': 393}}\n"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input=None,\n",
    "    stream_mode=\"updates\",\n",
    "    checkpoint_id=to_replay['checkpoint_id']\n",
    "):\n",
    "    if chunk.data:\n",
    "        assisant_node = chunk.data.get('assistant', {}).get('messages', [])\n",
    "        tool_node = chunk.data.get('tools', {}).get('messages', [])\n",
    "        if assisant_node:\n",
    "            print(\"-\" * 20+\"Assistant Node\"+\"-\" * 20)\n",
    "            print(assisant_node[-1])\n",
    "        elif tool_node:\n",
    "            print(\"-\" * 20+\"Tools Node\"+\"-\" * 20)\n",
    "            print(tool_node[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Assistant Node--------------------\n",
      "{'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'call_x7bq', 'function': {'arguments': '{\"a\": 2, \"b\": 3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'token_usage': {'completion_tokens': 19, 'prompt_tokens': 374, 'total_tokens': 393, 'completion_time': 0.069090909, 'prompt_time': 0.026095763, 'queue_time': 0.057646685999999996, 'total_time': 0.095186672}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--fe7d8149-944d-4e4f-b337-4a50faf332a0-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_x7bq', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 374, 'output_tokens': 19, 'total_tokens': 393}}\n"
     ]
    }
   ],
   "source": [
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "thread = await client.threads.create()\n",
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input=initial_input,\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    if chunk.data:\n",
    "        assisant_node = chunk.data.get('assistant', {}).get('messages', [])\n",
    "        tool_node = chunk.data.get('tools', {}).get('messages', [])\n",
    "        if assisant_node:\n",
    "            print(\"-\" * 20+\"Assistant Node\"+\"-\" * 20)\n",
    "            print(assisant_node[-1])\n",
    "        elif tool_node:\n",
    "            print(\"-\" * 20+\"Tools Node\"+\"-\" * 20)\n",
    "            print(tool_node[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': 'Multiply 2 and 3',\n",
       "   'additional_kwargs': {},\n",
       "   'response_metadata': {},\n",
       "   'type': 'human',\n",
       "   'name': None,\n",
       "   'id': 'a29062de-3c0d-4134-9e16-23f15ce907ca',\n",
       "   'example': False}]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = await client.threads.get_history(thread['thread_id'])\n",
    "to_fork = states[-2]\n",
    "to_fork['values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a29062de-3c0d-4134-9e16-23f15ce907ca'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fork['values']['messages'][0]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['assistant']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fork['next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1f0302ae-8d3d-688c-8000-5210b8fc5135'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_fork['checkpoint_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "forked_input = {\"messages\": HumanMessage(content=\"Multiply 3 and 3\",\n",
    "                                         id=to_fork['values']['messages'][0]['id'])}\n",
    "\n",
    "forked_config = await client.threads.update_state(\n",
    "    thread[\"thread_id\"],\n",
    "    forked_input,\n",
    "    checkpoint_id=to_fork['checkpoint_id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'checkpoint': {'thread_id': '0cf4afd6-cb52-4b65-be31-7d3709ace6c7',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0302b0-7f45-607a-8001-8cddfb2a87aa'},\n",
       " 'configurable': {'thread_id': '0cf4afd6-cb52-4b65-be31-7d3709ace6c7',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0302b0-7f45-607a-8001-8cddfb2a87aa'},\n",
       " 'checkpoint_id': '1f0302b0-7f45-607a-8001-8cddfb2a87aa'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forked_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'values': {'messages': [{'content': 'Multiply 3 and 3',\n",
       "    'additional_kwargs': {},\n",
       "    'response_metadata': {},\n",
       "    'type': 'human',\n",
       "    'name': None,\n",
       "    'id': 'a29062de-3c0d-4134-9e16-23f15ce907ca',\n",
       "    'example': False}]},\n",
       " 'next': ['assistant'],\n",
       " 'tasks': [{'id': '22a5de95-e173-d38e-d93b-bf05a3111e6b',\n",
       "   'name': 'assistant',\n",
       "   'path': ['__pregel_pull', 'assistant'],\n",
       "   'error': None,\n",
       "   'interrupts': [],\n",
       "   'checkpoint': None,\n",
       "   'state': None,\n",
       "   'result': None}],\n",
       " 'metadata': {'graph_id': 'agent',\n",
       "  'thread_id': '0cf4afd6-cb52-4b65-be31-7d3709ace6c7',\n",
       "  'checkpoint_id': '1f0302ae-8d3d-688c-8000-5210b8fc5135',\n",
       "  'checkpoint_ns': '',\n",
       "  'user-agent': 'langgraph-sdk-py/0.1.69',\n",
       "  'x-request-id': 'eca39265-40fc-41b2-a3df-190b44229366',\n",
       "  'langgraph_auth_user': None,\n",
       "  'langgraph_auth_user_id': '',\n",
       "  'langgraph_auth_permissions': [],\n",
       "  'langgraph_request_id': 'eca39265-40fc-41b2-a3df-190b44229366',\n",
       "  'assistant_id': 'fe096781-5601-53d2-b2f6-0d3403f7e9ca',\n",
       "  'user_id': '',\n",
       "  'created_by': 'system',\n",
       "  'run_attempt': 1,\n",
       "  'langgraph_version': '0.4.3',\n",
       "  'langgraph_plan': 'developer',\n",
       "  'langgraph_host': 'self-hosted',\n",
       "  'langgraph_api_url': 'http://127.0.0.1:2024',\n",
       "  'run_id': '1f0302ae-87ba-637e-85aa-97e38cb17873',\n",
       "  'source': 'update',\n",
       "  'writes': {'__start__': {'messages': {'content': 'Multiply 3 and 3',\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {},\n",
       "     'type': 'human',\n",
       "     'name': None,\n",
       "     'id': 'a29062de-3c0d-4134-9e16-23f15ce907ca',\n",
       "     'example': False}}},\n",
       "  'step': 1,\n",
       "  'parents': {}},\n",
       " 'created_at': '2025-05-13T18:49:42.366407+00:00',\n",
       " 'checkpoint': {'checkpoint_id': '1f0302b0-7f45-607a-8001-8cddfb2a87aa',\n",
       "  'thread_id': '0cf4afd6-cb52-4b65-be31-7d3709ace6c7',\n",
       "  'checkpoint_ns': ''},\n",
       " 'parent_checkpoint': {'checkpoint_id': '1f0302ae-8d3d-688c-8000-5210b8fc5135',\n",
       "  'thread_id': '0cf4afd6-cb52-4b65-be31-7d3709ace6c7',\n",
       "  'checkpoint_ns': ''},\n",
       " 'checkpoint_id': '1f0302b0-7f45-607a-8001-8cddfb2a87aa',\n",
       " 'parent_checkpoint_id': '1f0302ae-8d3d-688c-8000-5210b8fc5135'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = await client.threads.get_history(thread['thread_id'])\n",
    "states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Assistant Node--------------------\n",
      "{'content': '', 'additional_kwargs': {'tool_calls': [{'id': 'call_hmnj', 'function': {'arguments': '{\"a\": 3, \"b\": 3}', 'name': 'multiply'}, 'type': 'function'}]}, 'response_metadata': {'token_usage': {'completion_tokens': 19, 'prompt_tokens': 374, 'total_tokens': 393, 'completion_time': 0.069090909, 'prompt_time': 0.030441267, 'queue_time': 0.06015041199999999, 'total_time': 0.099532176}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'finish_reason': 'tool_calls', 'logprobs': None}, 'type': 'ai', 'name': None, 'id': 'run--ea896a24-30ea-4598-8e88-8e7e66548637-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 3, 'b': 3}, 'id': 'call_hmnj', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 374, 'output_tokens': 19, 'total_tokens': 393}}\n"
     ]
    }
   ],
   "source": [
    "async for chunk in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input=None,\n",
    "    stream_mode=\"updates\",\n",
    "    checkpoint_id=forked_config['checkpoint_id']\n",
    "):\n",
    "    if chunk.data:\n",
    "        assisant_node = chunk.data.get('assistant', {}).get('messages', [])\n",
    "        tool_node = chunk.data.get('tools', {}).get('messages', [])\n",
    "        if assisant_node:\n",
    "            print(\"-\" * 20+\"Assistant Node\"+\"-\" * 20)\n",
    "            print(assisant_node[-1])\n",
    "        elif tool_node:\n",
    "            print(\"-\" * 20+\"Tools Node\"+\"-\" * 20)\n",
    "            print(tool_node[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
