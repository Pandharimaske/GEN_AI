{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4533a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python langchain langchain-community langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ce692b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75944898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b79406d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "243723f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama3-70b-8192\",  # This is Groq's model naming for LLaMA 3\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "111051b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The classic \"Hello, World!\" It\\'s great to see you\\'re getting started with something new. What brings you here today? Do you have a project in mind, or are you just exploring? I\\'m here to help with any questions or topics you\\'d like to discuss!' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 12, 'total_tokens': 69, 'completion_time': 0.211721253, 'prompt_time': 0.000155577, 'queue_time': 0.058963651000000006, 'total_time': 0.21187683}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_dd4ae1c591', 'finish_reason': 'stop', 'logprobs': None} id='run--3a71dd31-c20d-404b-acb7-ba9fded8be1d-0' usage_metadata={'input_tokens': 12, 'output_tokens': 57, 'total_tokens': 69}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"Hello world\", name=\"Lance\")\n",
    "\n",
    "# Message list\n",
    "messages = [msg]\n",
    "\n",
    "# Invoke the model with a list of messages \n",
    "print(llm.invoke(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e684ec77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The classic \"Hello, World!\" greeting!\\n\\nIt\\'s great to see you here. Is there something I can help you with, or would you like to chat about something in particular? I\\'m all ears (or rather, all text)!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 12, 'total_tokens': 61, 'completion_time': 0.14, 'prompt_time': 0.000160557, 'queue_time': 0.054759223, 'total_time': 0.140160557}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_dd4ae1c591', 'finish_reason': 'stop', 'logprobs': None}, id='run--8a3213dc-bc24-44df-9b1d-545777104e66-0', usage_metadata={'input_tokens': 12, 'output_tokens': 49, 'total_tokens': 61})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b94381",
   "metadata": {},
   "source": [
    "### Search Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe431984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b08b1cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "search_docs = tavily_search.invoke(\"What is LangGraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d84a63a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'What Is LangGraph and How to Use It? - DataCamp',\n",
       "  'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
       "  'content': 'LangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner.\\nIt simplifies the development process by enabling the creation of cyclical graphs, which are essential for developing agent runtimes. With LangGraph, we can easily build robust, scalable, and flexible multi-agent systems. [...] Home\\nTutorials\\n\\nLangGraph Tutorial: What Is LangGraph and How to Use It?\\nLangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner.\\nContents\\nJun 26, 2024 \\xa0· 12 min read\\nContents\\n\\nWhat Is LangGraph?\\nGraph structure\\nState management\\n\\nCoordination\\n\\n\\nWhy LangGraph?\\n\\nSimplified development\\nFlexibility\\nScalability\\n\\nFault tolerance\\n\\n\\nGetting Started With LangGraph [...] If you want to learn more about the LangChain ecosystem, I recommend this introduction to LangChain.\\nWhat Is LangGraph?\\nLangGraph enables us to create stateful, multi-actor applications utilizing LLMs as easily as possible. It extends the capabilities of LangChain, introducing the ability to create and manage cyclical graphs, which are pivotal for developing sophisticated agent runtimes. The core concepts of LangGraph include: graph structure, state management, and coordination.\\nGraph structure',\n",
       "  'score': 0.93844646},\n",
       " {'title': 'LangGraph - LangChain',\n",
       "  'url': 'https://www.langchain.com/langgraph',\n",
       "  'content': 'LangGraph is a stateful, orchestration framework that brings added control to agent workflows. LangGraph Platform is a service for deploying and scaling LangGraph applications, with an opinionated API for building agent UXs, plus an integrated developer studio.\\nLangGraph (open source)\\nLangGraph Platform\\nFeatures\\nDescription\\nStateful orchestration framework for agentic applications\\nScalable infrastructure for deploying LangGraph applications  \\nSDKs\\nPython and JavaScript\\nPython and JavaScript',\n",
       "  'score': 0.93624437},\n",
       " {'title': 'LangGraph - GitHub Pages',\n",
       "  'url': 'https://langchain-ai.github.io/langgraph/',\n",
       "  'content': 'Note\\nLooking for the JS version? See the JS repo and the JS docs.\\nLangGraph is a low-level orchestration framework for building controllable agents. While LangChain provides integrations and composable components to streamline LLM application development, the LangGraph library enables agent orchestration — offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.\\nGet started¶\\nFirst, install LangGraph:',\n",
       "  'score': 0.93497354}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0925ce93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f5f26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
