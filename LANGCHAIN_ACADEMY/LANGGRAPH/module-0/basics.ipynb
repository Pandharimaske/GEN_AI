{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4533a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python langchain langchain-community langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ce692b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75944898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b79406d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "243723f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama3-70b-8192\",  # This is Groq's model naming for LLaMA 3\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "111051b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The classic \"Hello, World!\" It\\'s great to see you\\'re getting started with something new. What brings you here today? Do you have a project in mind, or are you just exploring? I\\'m here to help with any questions or topics you\\'d like to discuss!' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 12, 'total_tokens': 69, 'completion_time': 0.213266428, 'prompt_time': 0.000139819, 'queue_time': 0.080021981, 'total_time': 0.213406247}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_dd4ae1c591', 'finish_reason': 'stop', 'logprobs': None} id='run--e8117ccf-5214-4ce6-a23d-cfd45809bd94-0' usage_metadata={'input_tokens': 12, 'output_tokens': 57, 'total_tokens': 69}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"Hello world\", name=\"Lance\")\n",
    "\n",
    "# Message list\n",
    "messages = [msg]\n",
    "\n",
    "# Invoke the model with a list of messages \n",
    "print(llm.invoke(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e684ec77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The classic \"Hello, World!\" greeting!\\n\\nIt\\'s great to see you here. Is there something I can help you with, or would you like to chat about something in particular? I\\'m all ears (or rather, all text)!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 12, 'total_tokens': 61, 'completion_time': 0.14, 'prompt_time': 0.000184129, 'queue_time': 0.058301391, 'total_time': 0.140184129}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_dd4ae1c591', 'finish_reason': 'stop', 'logprobs': None}, id='run--f05f800b-d550-4b1f-877b-3adde7c33c09-0', usage_metadata={'input_tokens': 12, 'output_tokens': 49, 'total_tokens': 61})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b94381",
   "metadata": {},
   "source": [
    "### Search Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe431984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b08b1cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "search_docs = tavily_search.invoke(\"What is LangGraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d84a63a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'What is LangGraph? - Analytics Vidhya',\n",
       "  'url': 'https://www.analyticsvidhya.com/blog/2024/07/langgraph-revolutionizing-ai-agent/',\n",
       "  'content': 'To sum up, LangGraph is a major advancement in the development of AI agents. It enables developers to push the limits of what’s possible with AI agents by eliminating the shortcomings of earlier systems and offering a flexible, graph-based framework for agent construction and execution. LangGraph is positioned to influence the direction of artificial intelligence significantly in the future. [...] Frameworks such as LangGraph are becoming increasingly important as AI develops. LangGraph is making the next generation of AI applications possible by offering a versatile and strong framework for developing and overseeing AI agents. [...] In this way, we can add different kinds of tools to the LLM so that we can get our queries answered even if LLM alone can’t answer. Thus LLM agents will be far more useful in many scanarios.\\n\\nWhat LangGraph Offers?\\n\\nLangGraph offers a powerful toolset for building complex AI systems. It provides a framework for creating agentic systems that can reason, make decisions, and interact with multiple data sources. Key features include:\\n\\nReal-World Example of LangGraph',\n",
       "  'score': 0.947386},\n",
       " {'title': 'What Is LangGraph and How to Use It? - DataCamp',\n",
       "  'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
       "  'content': 'LangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner.\\nIt simplifies the development process by enabling the creation of cyclical graphs, which are essential for developing agent runtimes. With LangGraph, we can easily build robust, scalable, and flexible multi-agent systems. [...] Home\\nTutorials\\n\\nLangGraph Tutorial: What Is LangGraph and How to Use It?\\nLangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner.\\nContents\\nJun 26, 2024 \\xa0· 12 min read\\nContents\\n\\nWhat Is LangGraph?\\nGraph structure\\nState management\\n\\nCoordination\\n\\n\\nWhy LangGraph?\\n\\nSimplified development\\nFlexibility\\nScalability\\n\\nFault tolerance\\n\\n\\nGetting Started With LangGraph [...] If you want to learn more about the LangChain ecosystem, I recommend this introduction to LangChain.\\nWhat Is LangGraph?\\nLangGraph enables us to create stateful, multi-actor applications utilizing LLMs as easily as possible. It extends the capabilities of LangChain, introducing the ability to create and manage cyclical graphs, which are pivotal for developing sophisticated agent runtimes. The core concepts of LangGraph include: graph structure, state management, and coordination.\\nGraph structure',\n",
       "  'score': 0.93844646},\n",
       " {'title': 'LangGraph - LangChain',\n",
       "  'url': 'https://www.langchain.com/langgraph',\n",
       "  'content': 'LangGraph is a stateful, orchestration framework that brings added control to agent workflows. LangGraph Platform is a service for deploying and scaling LangGraph applications, with an opinionated API for building agent UXs, plus an integrated developer studio.\\nLangGraph (open source)\\nLangGraph Platform\\nFeatures\\nDescription\\nStateful orchestration framework for agentic applications\\nScalable infrastructure for deploying LangGraph applications  \\nSDKs\\nPython and JavaScript\\nPython and JavaScript',\n",
       "  'score': 0.93624437}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0925ce93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
