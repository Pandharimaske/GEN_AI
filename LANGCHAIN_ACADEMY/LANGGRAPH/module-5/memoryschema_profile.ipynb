{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <B> Chatbot with Profile Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain_openai langgraph trustcall langchain_core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a user profile schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict , List\n",
    "\n",
    "class UserProfile(TypedDict):\n",
    "    \"\"\"User profile schema with typed fields\"\"\"\n",
    "    user_name: str # The user's prefered name\n",
    "    interests: List[str] # A list of the user's interests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a schema to the store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Pandhari', 'interests': ['biking', 'technology', 'coffee']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TypedDict instance\n",
    "user_profile: UserProfile = {\n",
    "    \"user_name\": \"Pandhari\" , \n",
    "    \"interests\": [\"biking\" , \"technology\" , \"coffee\"]\n",
    "}\n",
    "user_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Initialize the in-memory store\n",
    "in_memory_store = InMemoryStore()\n",
    "\n",
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace_for_memory = (user_id , \"memory\")\n",
    "\n",
    "# Save a memory to namespace as key and value\n",
    "key = \"user_profile\"\n",
    "value = user_profile\n",
    "in_memory_store.put(namespace_for_memory , key , value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'namespace': ['1', 'memory'], 'key': 'user_profile', 'value': {'user_name': 'Pandhari', 'interests': ['biking', 'technology', 'coffee']}, 'created_at': '2025-05-21T04:10:47.836536+00:00', 'updated_at': '2025-05-21T04:10:47.836538+00:00', 'score': None}\n"
     ]
    }
   ],
   "source": [
    "# Search\n",
    "for m in in_memory_store.search(namespace_for_memory):\n",
    "    print(m.dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Pandhari', 'interests': ['biking', 'technology', 'coffee']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the memory by namespace and key\n",
    "profile = in_memory_store.get(namespace_for_memory , \"user_profile\")\n",
    "profile.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot with profile schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Pandhari', 'interests': ['biking']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel , Field\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatGroq(model=os.getenv(\"GROQ_MODEL_NAME\") , temperature=0)\n",
    "\n",
    "# Bind schema to model\n",
    "model_with_structure = model.with_structured_output(UserProfile)\n",
    "\n",
    "# Invoke the model to produce structured output that matches the schema\n",
    "structured_output = model_with_structure.invoke([HumanMessage(\"My name is Pandhari, I like to bike\")])\n",
    "structured_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful assistant with memory that provides information about the user. \n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "Here is the memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "# Create new memory from the chat history and any existing memory\n",
    "CREATE_MEMORY_INSTRUCTION = \"\"\"Create or update a user profile memory based on the user's chat history. \n",
    "This will be saved for long-term memory. If there is an existing memory, simply update it. \n",
    "Here is the existing memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Load memory from the store and use it to personalize the chatbot's response.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"\n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "\n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and save a memory to the store.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve existing memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"\n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "        \n",
    "    # Format the existing memory in the instruction\n",
    "    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=formatted_memory)\n",
    "\n",
    "    # Invoke the model to produce structured output that matches the schema\n",
    "    new_memory = model_with_structure.invoke([SystemMessage(content=system_msg)]+state['messages'])\n",
    "\n",
    "    # Overwrite the existing use profile memory\n",
    "    key = \"user_memory\"\n",
    "    store.put(namespace, key, new_memory)\n",
    "\n",
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Pandhari and I like to bike around Pune and eat at bakeries.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Welcome back, Pandhari. I remember we spoke earlier about your interests in biking around Pune and trying out bakeries. How's your biking adventure been lately? Have you discovered any new favorite bakeries or routes in Pune that you'd like to share?\n",
      "\n",
      "I still have your information stored: \n",
      "Name: Pandhari\n",
      "Interests: Biking, trying bakeries in Pune\n",
      "\n",
      "By the way, I also met someone named Lance who shares similar interests, but he's based in San Francisco. Maybe one day you two can exchange tips on the best biking routes and bakeries in your respective cities!\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Hi, my name is Pandhari and I like to bike around Pune and eat at bakeries.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Pandhari', 'interests': ['biking', 'trying bakeries in Pune']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace = (\"memory\", user_id)\n",
    "existing_memory = across_thread_memory.get(namespace, \"user_memory\")\n",
    "existing_memory.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When can this fail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "class OutputFormat(BaseModel):\n",
    "    preference: str\n",
    "    sentence_preference_revealed: str\n",
    "\n",
    "class TelegramPreferences(BaseModel):\n",
    "    preferred_encoding: Optional[List[OutputFormat]] = None\n",
    "    favorite_telegram_operators: Optional[List[OutputFormat]] = None\n",
    "    preferred_telegram_paper: Optional[List[OutputFormat]] = None\n",
    "\n",
    "class MorseCode(BaseModel):\n",
    "    preferred_key_type: Optional[List[OutputFormat]] = None\n",
    "    favorite_morse_abbreviations: Optional[List[OutputFormat]] = None\n",
    "\n",
    "class Semaphore(BaseModel):\n",
    "    preferred_flag_color: Optional[List[OutputFormat]] = None\n",
    "    semaphore_skill_level: Optional[List[OutputFormat]] = None\n",
    "\n",
    "class TrustFallPreferences(BaseModel):\n",
    "    preferred_fall_height: Optional[List[OutputFormat]] = None\n",
    "    trust_level: Optional[List[OutputFormat]] = None\n",
    "    preferred_catching_technique: Optional[List[OutputFormat]] = None\n",
    "\n",
    "class CommunicationPreferences(BaseModel):\n",
    "    telegram: TelegramPreferences\n",
    "    morse_code: MorseCode\n",
    "    semaphore: Semaphore\n",
    "\n",
    "class UserPreferences(BaseModel):\n",
    "    communication_preferences: CommunicationPreferences\n",
    "    trust_fall_preferences: TrustFallPreferences\n",
    "\n",
    "class TelegramAndTrustFallPreferences(BaseModel):\n",
    "    pertinent_user_preferences: UserPreferences\n",
    "\n",
    "# Add description manually\n",
    "TelegramAndTrustFallPreferences.__doc__ = \"Extracts the user's telegram and trust fall preferences from a conversation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import ValidationError\n",
    "\n",
    "# Bind schema to model\n",
    "model_with_structure = model.with_structured_output(TelegramAndTrustFallPreferences)\n",
    "\n",
    "# Conversation\n",
    "conversation = \"\"\"Operator: How may I assist with your telegram, sir?\n",
    "Customer: I need to send a message about our trust fall exercise.\n",
    "Operator: Certainly. Morse code or standard encoding?\n",
    "Customer: Morse, please. I love using a straight key.\n",
    "Operator: Excellent. What's your message?\n",
    "Customer: Tell him I'm ready for a higher fall, and I prefer the diamond formation for catching.\n",
    "Operator: Done. Shall I use our \"Daredevil\" paper for this daring message?\n",
    "Customer: Perfect! Send it by your fastest carrier pigeon.\n",
    "Operator: It'll be there within the hour, sir.\"\"\"\n",
    "\n",
    "# Invoke the model\n",
    "try:\n",
    "    model_with_structure.invoke(f\"\"\"Extract the preferences from the following conversation:\n",
    "    <convo>\n",
    "    {conversation}\n",
    "    </convo>\"\"\")\n",
    "except ValidationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trustcall for creating and updating profile schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversation\n",
    "conversation = [HumanMessage(content=\"Hi, I'm Pandhari.\"), \n",
    "                AIMessage(content=\"Nice to meet you, Pandhari.\"), \n",
    "                HumanMessage(content=\"I really like biking around Pune Maharashtra.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "\n",
    "# Schema\n",
    "class UserProfile(BaseModel):\n",
    "    \"\"\"User profile schema with typed fields\"\"\"\n",
    "    user_name: str = Field(description=\"The user's preffered name\")\n",
    "    interests: List[str] = Field(description=\"A list of the user's interests\")\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatGroq(model=os.getenv(\"GROQ_MODEL_NAME\") , temperature=0)\n",
    "\n",
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model , \n",
    "    tools=[UserProfile] , \n",
    "    tool_choice=\"UserProfile\"\n",
    ")\n",
    "\n",
    "# Instruction\n",
    "system_msg = \"Extract the user profile from the following conversation\"\n",
    "\n",
    "# Invoke the extractor\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=system_msg)] + conversation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UserProfile (call_3z66)\n",
      " Call ID: call_3z66\n",
      "  Args:\n",
      "    user_name: Pandhari\n",
      "    interests: ['biking']\n"
     ]
    }
   ],
   "source": [
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UserProfile(user_name='Pandhari', interests=['biking'])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = result[\"responses\"]\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Pandhari', 'interests': ['biking']}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema[0].model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'call_3z66'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"response_metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the conversation\n",
    "updated_conversation = [HumanMessage(content=\"Hi, I'm Pandhari.\"), \n",
    "                        AIMessage(content=\"Nice to meet you, Pandhari.\"), \n",
    "                        HumanMessage(content=\"I really like biking around Pune.\"),\n",
    "                        AIMessage(content=\"Pune is a great city! Where do you go after biking?\"),\n",
    "                        HumanMessage(content=\"I really like to go to a bakery after biking.\"),]\n",
    "\n",
    "# Update the instruction\n",
    "system_msg = f\"\"\"Update the memory (JSON doc) to incorporate new information from the following conversation\"\"\"\n",
    "\n",
    "# Invoke the extractor with the updated instruction and existing profile with the corresponding tool name (UserProfile)\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=system_msg)]+updated_conversation}, \n",
    "                                    {\"existing\": {\"UserProfile\": schema[0].model_dump()}}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UserProfile (call_6jdn)\n",
      " Call ID: call_6jdn\n",
      "  Args:\n",
      "    user_name: Pandhari\n",
      "    interests: ['biking', 'bakery']\n"
     ]
    }
   ],
   "source": [
    "for m in result[\"messages\"]: \n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'call_6jdn'}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"response_metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Pandhari', 'interests': ['biking', 'bakery']}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_schema = result[\"responses\"][0]\n",
    "updated_schema.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'call_6jdn'}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"response_metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TelegramAndTrustFallPreferences(pertinent_user_preferences=UserPreferences(communication_preferences=CommunicationPreferences(telegram=TelegramPreferences(preferred_encoding=[OutputFormat(preference='Morse code', sentence_preference_revealed='Morse, please')], favorite_telegram_operators=None, preferred_telegram_paper=[OutputFormat(preference='Daredevil', sentence_preference_revealed='Perfect!')]), morse_code=MorseCode(preferred_key_type=[OutputFormat(preference='straight key', sentence_preference_revealed='I love using a straight key')], favorite_morse_abbreviations=None), semaphore=Semaphore(preferred_flag_color=None, semaphore_skill_level=None)), trust_fall_preferences=TrustFallPreferences(preferred_fall_height=[OutputFormat(preference='higher fall', sentence_preference_revealed=\"I'm ready for a higher fall\")], trust_level=None, preferred_catching_technique=[OutputFormat(preference='diamond formation', sentence_preference_revealed='I prefer the diamond formation for catching')])))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bound = create_extractor(\n",
    "    model,\n",
    "    tools=[TelegramAndTrustFallPreferences],\n",
    "    tool_choice=\"TelegramAndTrustFallPreferences\",\n",
    ")\n",
    "\n",
    "# Conversation\n",
    "conversation = \"\"\"Operator: How may I assist with your telegram, sir?\n",
    "Customer: I need to send a message about our trust fall exercise.\n",
    "Operator: Certainly. Morse code or standard encoding?\n",
    "Customer: Morse, please. I love using a straight key.\n",
    "Operator: Excellent. What's your message?\n",
    "Customer: Tell him I'm ready for a higher fall, and I prefer the diamond formation for catching.\n",
    "Operator: Done. Shall I use our \"Daredevil\" paper for this daring message?\n",
    "Customer: Perfect! Send it by your fastest carrier pigeon.\n",
    "Operator: It'll be there within the hour, sir.\"\"\"\n",
    "\n",
    "result = bound.invoke(\n",
    "    f\"\"\"Extract the preferences from the following conversation:\n",
    "<convo>\n",
    "{conversation}\n",
    "</convo>\"\"\"\n",
    ")\n",
    "\n",
    "# Extract the preferences\n",
    "result[\"responses\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot with profile schema updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatGroq(model=os.getenv(\"GROQ_MODEL_NAME\"), temperature=0)\n",
    "\n",
    "# Schema \n",
    "class UserProfile(BaseModel):\n",
    "    \"\"\" Profile of a user \"\"\"\n",
    "    user_name: str = Field(description=\"The user's preferred name\")\n",
    "    user_location: str = Field(description=\"The user's location\")\n",
    "    interests: list = Field(description=\"A list of the user's interests\")\n",
    "\n",
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[UserProfile],\n",
    "    tool_choice=\"UserProfile\", # Enforces use of the UserProfile tool\n",
    ")\n",
    "\n",
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful assistant with memory that provides information about the user. \n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "Here is the memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "# Extraction instruction\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"Create or update the memory (JSON doc) to incorporate information from the following conversation:\"\"\"\n",
    "\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Load memory from the store and use it to personalize the chatbot's response.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "\n",
    "    # Format the memories for the system prompt\n",
    "    if existing_memory and existing_memory.value:\n",
    "        memory_dict = existing_memory.value\n",
    "        formatted_memory = (\n",
    "            f\"Name: {memory_dict.get('user_name', 'Unknown')}\\n\"\n",
    "            f\"Location: {memory_dict.get('user_location', 'Unknown')}\\n\"\n",
    "            f\"Interests: {', '.join(memory_dict.get('interests', []))}\"      \n",
    "        )\n",
    "    else:\n",
    "        formatted_memory = None\n",
    "\n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=formatted_memory)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and save a memory to the store.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve existing memory from the store\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "        \n",
    "    # Get the profile as the value from the list, and convert it to a JSON doc\n",
    "    existing_profile = {\"UserProfile\": existing_memory.value} if existing_memory else None\n",
    "    \n",
    "    # Invoke the extractor\n",
    "    result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=TRUSTCALL_INSTRUCTION)]+state[\"messages\"], \"existing\": existing_profile})\n",
    "    \n",
    "    # Get the updated profile as a JSON object\n",
    "    updated_profile = result[\"responses\"][0].model_dump()\n",
    "\n",
    "    # Save the updated profile\n",
    "    key = \"user_memory\"\n",
    "    store.put(namespace, key, updated_profile)\n",
    "\n",
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# Compile the graph with the checkpointer fir and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Pandhari\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Pandhari, it's nice to meet you. I don't have any prior information about you, so let's start fresh. Is there something I can help you with or would you like to chat? I'll make sure to remember our conversation for next time.\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Hi, my name is Pandhari\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to bike around San Francisco\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "San Francisco is a beautiful city with a lot of great bike routes. I've updated my memory with your name and location, so I can address you personally next time. \n",
      "\n",
      "As for your interest in biking, San Francisco has many scenic bike paths, such as the Golden Gate Park, the Presidio, and the Embarcadero. Have you explored any of these routes, or is there a particular area you enjoy biking in?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I like to bike around San Francisco\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'namespace': ['memory', '1'],\n",
       " 'key': 'user_memory',\n",
       " 'value': {'user_name': 'Pandhari',\n",
       "  'user_location': 'San Francisco',\n",
       "  'interests': ['biking']},\n",
       " 'created_at': '2025-05-21T06:20:03.462596+00:00',\n",
       " 'updated_at': '2025-05-21T06:20:03.462597+00:00'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "namespace = (\"memory\", user_id)\n",
    "existing_memory = across_thread_memory.get(namespace, \"user_memory\")\n",
    "existing_memory.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 'Pandhari',\n",
       " 'user_location': 'San Francisco',\n",
       " 'interests': ['biking']}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The user profile saved as a JSON object\n",
    "existing_memory.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I also enjoy going to bakeries\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Bakeries can be a wonderful treat after a long bike ride. San Francisco has a vibrant food scene, with many excellent bakeries to choose from. I'll make sure to remember your interest in bakeries, along with your love of biking.\n",
      "\n",
      "If you're looking for recommendations, I can suggest some popular bakeries in San Francisco. For example, there's Bi-Rite Bakery, Noe Valley Bakery, or even the famous Tartine Bakery. Have you tried any of these, or is there a particular type of baked good you enjoy?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I also enjoy going to bakeries\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What bakeries do you recommend for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Pandhari, I'm glad you asked. Given your love for bakeries and your location in San Francisco, I'd like to recommend a few spots that are worth checking out. \n",
      "\n",
      "First, there's Bi-Rite Bakery, a popular spot in the Mission District that's known for its delicious pastries, bread, and cakes. They also have a great selection of sandwiches and salads if you're looking for a light bite.\n",
      "\n",
      "Another great option is Noe Valley Bakery, which offers a wide variety of sweet and savory treats, including their famous sourdough bread. They also have a cozy atmosphere, making it a great spot to grab a coffee and pastry on a lazy morning.\n",
      "\n",
      "If you're looking for something a bit more unique, you might want to try Tartine Bakery, which is known for its creative and delicious breads, pastries, and desserts. They also have a great selection of sandwiches and salads, and their outdoor seating area is a great spot to enjoy a meal on a nice day.\n",
      "\n",
      "Lastly, since you enjoy biking, I thought I'd mention that all of these bakeries are relatively bike-friendly, with bike racks or nearby parking options. You could even consider biking to one of these spots and enjoying a pastry or sandwich as a reward after your ride.\n",
      "\n",
      "I hope you enjoy trying out these recommendations, Pandhari! Do you have a favorite type of pastry or bread that you're particularly craving?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"What bakeries do you recommend for me?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
